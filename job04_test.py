import pandas as pd
import pickle
from konlpy.tag import Okt
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# ğŸ”¹ 1. ì„±ê²½ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì „ì²˜ë¦¬ëœ CSV íŒŒì¼)
bible_file = "./data/processed_bible.csv"
df = pd.read_csv(bible_file)

# ğŸ”¹ 2. TF-IDF ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
#   - TF-IDF: ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²• (ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜)
#   - vectorizer: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê°ì²´
#   - tfidf_matrix: ì„±ê²½ êµ¬ì ˆ ì „ì²´ë¥¼ ë²¡í„°í™”í•œ ê²°ê³¼
with open("./data/tfidf_vectorizer.pkl", "rb") as f:
    vectorizer = pickle.load(f)
with open("./data/tfidf_matrix.pkl", "rb") as f:
    tfidf_matrix = pickle.load(f)

# ğŸ”¹ 3. Word2Vec ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
#   - ë‹¨ì–´ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ëª¨ë¸
word2vec_model = Word2Vec.load("./models/word2vec_bible.model")

# ğŸ”¹ 4. í˜•íƒœì†Œ ë¶„ì„ê¸° ë° ë¶ˆìš©ì–´ ëª©ë¡ ì„¤ì •
#   - Okt: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ)
#   - ë¶ˆìš©ì–´(stopwords): ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ì œê±°ë¥¼ ìœ„í•´ ì‚¬ìš©
okt = Okt()
stopwords_df = pd.read_csv("./StopWord/stopwords.csv")
stopwords = set(stopwords_df["stopword"].tolist())

# ğŸ”¹ 5. ë°ì´í„° í¬ê¸° ë§ì¶”ê¸°
#   - TF-IDF ë²¡í„°í™” ê³¼ì •ì—ì„œ ì¼ë¶€ í–‰ì´ ì‚­ì œë  ìˆ˜ ìˆìŒ
#   - dfì˜ í¬ê¸°ë¥¼ tfidf_matrix í¬ê¸°ì— ë§ì¶° ì¡°ì •
df = df.iloc[:tfidf_matrix.shape[0]]


# ğŸ”¹ 6. ê¸°ë„ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_keywords(prayer_text, top_n=5):
    """
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸°ë„ ì œëª©ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.

    1. í˜•íƒœì†Œ ë¶„ì„ì„ í†µí•´ ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
    2. ë¶ˆìš©ì–´(stopwords) ì œê±°
    3. TF-IDF ê°’ì´ ë†’ì€ ìƒìœ„ top_nê°œì˜ í‚¤ì›Œë“œë¥¼ ì„ íƒ

    :param prayer_text: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸°ë„ ì œëª© (ë¬¸ì¥)
    :param top_n: ì¶”ì¶œí•  í‚¤ì›Œë“œ ê°œìˆ˜ (ê¸°ë³¸ê°’ 5ê°œ)
    :return: ìµœì¢…ì ìœ¼ë¡œ ì„ íƒëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # 1ï¸âƒ£ í˜•íƒœì†Œ ë¶„ì„ ë° í’ˆì‚¬ íƒœê¹… (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì„ íƒ)
    processed_prayer = [word for word, pos in okt.pos(prayer_text, stem=True) if pos in ["Noun", "Verb", "Adjective"]]

    # 2ï¸âƒ£ ë¶ˆìš©ì–´ ì œê±°
    filtered_prayer = [word for word in processed_prayer if word not in stopwords]

    # 3ï¸âƒ£ TF-IDF ë‹¨ì–´ ëª©ë¡ì—ì„œ ê¸°ë„ ì œëª©ê³¼ ê²¹ì¹˜ëŠ” ë‹¨ì–´ë§Œ ì„ íƒ
    keyword_candidates = [word for word in filtered_prayer if word in vectorizer.get_feature_names_out()]

    # 4ï¸âƒ£ TF-IDF ê°’ì´ ë†’ì€ ë‹¨ì–´ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ Nê°œ ì„ íƒ
    keyword_candidates = sorted(keyword_candidates,
                                key=lambda w: tfidf_matrix[:, vectorizer.vocabulary_.get(w, 0)].sum(),
                                reverse=True)[:top_n]

    return keyword_candidates


# ğŸ”¹ 7. Word2Vec ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def get_word2vec_similarity(keywords, verse_words):
    """
    ì„±ê²½ êµ¬ì ˆê³¼ ê¸°ë„ ì œëª© í‚¤ì›Œë“œ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.

    1. ê¸°ë„ ì œëª©ì˜ ê° í‚¤ì›Œë“œì™€ ì„±ê²½ êµ¬ì ˆì˜ ê° ë‹¨ì–´ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
    2. ëª¨ë“  ìœ ì‚¬ë„ì˜ í‰ê· ê°’ì„ ë°˜í™˜

    :param keywords: ê¸°ë„ ì œëª©ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    :param verse_words: ì„±ê²½ êµ¬ì ˆì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë¦¬ìŠ¤íŠ¸
    :return: í‰ê·  ìœ ì‚¬ë„ ê°’ (0~1)
    """
    similarities = []

    for keyword in keywords:
        for word in verse_words:
            # ë‹¨ì–´ê°€ Word2Vec ëª¨ë¸ì— ìˆì„ ê²½ìš° ìœ ì‚¬ë„ ê³„ì‚°
            if keyword in word2vec_model.wv and word in word2vec_model.wv:
                similarities.append(word2vec_model.wv.similarity(keyword, word))

    # í‰ê·  ìœ ì‚¬ë„ ê°’ ë°˜í™˜ (ìœ ì‚¬ë„ ê°’ì´ ì—†ìœ¼ë©´ 0 ë°˜í™˜)
    return np.mean(similarities) if similarities else 0


# ğŸ”¹ 8. ì„±ê²½ êµ¬ì ˆ ì¶”ì²œ í•¨ìˆ˜
def recommend_verse(prayer_text):
    """
    ê¸°ë„ ì œëª©ì„ ì…ë ¥ë°›ì•„ ê´€ë ¨ëœ ì„±ê²½ êµ¬ì ˆì„ ì¶”ì²œí•˜ëŠ” í•¨ìˆ˜.

    1. ê¸°ë„ ì œëª©ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
    2. TF-IDF ìœ ì‚¬ë„ ê³„ì‚°
    3. Word2Vec ìœ ì‚¬ë„ ê³„ì‚°
    4. ë‘ ìœ ì‚¬ë„ë¥¼ ê²°í•© (TF-IDF 70% + Word2Vec 30%)
    5. ê°€ì¥ ìœ ì‚¬í•œ 3ê°œì˜ ì„±ê²½ êµ¬ì ˆ ì¶œë ¥

    :param prayer_text: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸°ë„ ì œëª© (ë¬¸ì¥)
    """
    keywords = extract_keywords(prayer_text, top_n=5)

    if not keywords:
        print("\nâš ï¸ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    print("\nğŸ” ì„ íƒëœ í‚¤ì›Œë“œ:", keywords)

    # 1ï¸âƒ£ TF-IDF ìœ ì‚¬ë„ ê³„ì‚° (ê¸°ë„ ì œëª©ê³¼ ì„±ê²½ êµ¬ì ˆ ê°„ì˜ ìœ ì‚¬ë„)
    query_vector = vectorizer.transform([" ".join(keywords)])
    cosine_sim = cosine_similarity(query_vector, tfidf_matrix)

    # 2ï¸âƒ£ Word2Vec ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„)
    df["word2vec_sim"] = df["processed"].apply(
        lambda x: get_word2vec_similarity(keywords, str(x).split()) if isinstance(x, str) else 0)

    # 3ï¸âƒ£ TF-IDF ìœ ì‚¬ë„(70%) + Word2Vec ìœ ì‚¬ë„(30%) ê²°í•©
    final_scores = (cosine_sim[0] * 0.7) + (df["word2vec_sim"].values * 0.3)

    # 4ï¸âƒ£ ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ 3ê°œ ì„±ê²½ êµ¬ì ˆ ì°¾ê¸°
    top_indices = np.argsort(final_scores)[-3:][::-1]

    # 5ï¸âƒ£ ì¶”ì²œ ì„±ê²½ êµ¬ì ˆ ì¶œë ¥
    print("\nğŸ“– ì¶”ì²œ ì„±ê²½ ë§ì”€:")
    for idx in top_indices:
        print(f"{df.iloc[idx]['book']} {df.iloc[idx]['chapter']}:{df.iloc[idx]['verse']} - {df.iloc[idx]['content']}")


# ğŸ”¹ 9. ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì„±ê²½ êµ¬ì ˆ ì¶”ì²œ ì‹¤í–‰
while True:
    prayer_input = input("\nğŸ™ ê¸°ë„ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
    if prayer_input.lower() == "exit":
        break
    recommend_verse(prayer_input)
