import pandas as pd
from konlpy.tag import Okt
from gensim.models import Word2Vec

# ğŸ”¹ 1. CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path = "./data/merged_bible (2).csv"  # íŒŒì¼ ê²½ë¡œ ë³€ê²½ í•„ìš”
df = pd.read_csv(file_path)

# ğŸ”¹ 2. ë°ì´í„° ì „ì²˜ë¦¬ (ë§ì”€ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°)
df.dropna(inplace=True)
df['content'] = df['content'].astype(str).str.replace(r'[^ê°€-í£\s]', '', regex=True)

# ğŸ”¹ 3. í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ)
okt = Okt()
df['tokenized'] = df['content'].apply(lambda x: [word for word, pos in okt.pos(x, stem=True) if pos in ['Noun', 'Verb', 'Adjective']])

# ğŸ”¹ 4. Word2Vec ëª¨ë¸ í•™ìŠµ
sentences = df['tokenized'].tolist()
word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4, epochs=20)

# ëª¨ë¸ ì €ì¥ (í•„ìš” ì‹œ)
word2vec_model.save('./models/word2vec_bible.model')
print("âœ… Word2Vec ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")