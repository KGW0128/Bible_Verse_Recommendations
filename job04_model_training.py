
#ëª¨ë¸í•™ìŠµ(ìŠ¤ì¼€ì¼ ì „)

# import pandas as pd
# from konlpy.tag import Okt
# from gensim.models import Word2Vec
#
# # ğŸ”¹ 1. CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# file_path = "./data/merged_bible.csv"  # íŒŒì¼ ê²½ë¡œ ë³€ê²½ í•„ìš”
# df = pd.read_csv(file_path)
#
# # ğŸ”¹ 2. ë°ì´í„° ì „ì²˜ë¦¬ (ë§ì”€ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°)
# df.dropna(inplace=True)
# df['content'] = df['content'].astype(str).str.replace(r'[^ê°€-í£\s]', '', regex=True)
#
# # ğŸ”¹ 3. í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ)
# okt = Okt()
# df['tokenized'] = df['content'].apply(lambda x: [word for word, pos in okt.pos(x, stem=True) if pos in ['Noun', 'Verb', 'Adjective']])
#
# # ğŸ”¹ 4. Word2Vec ëª¨ë¸ í•™ìŠµ
# sentences = df['tokenized'].tolist()
# word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4, epochs=20)
#
# # ëª¨ë¸ ì €ì¥ (í•„ìš” ì‹œ)
# word2vec_model.save('./models/word2vec_bible.model')
# print("âœ… Word2Vec ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")



#----------------------------------------------------------------------

#ëª¨ë¸í•™ìŠµ(ìŠ¤ì¼€ì¼ í›„)

import pandas as pd
import random
from gensim.models import Word2Vec
from collections import Counter

# ğŸ”¹ 1. CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path = "./data/processed_bible.csv"  # ì „ì²˜ë¦¬ëœ ì„±ê²½ ë°ì´í„°
df = pd.read_csv(file_path)

# ğŸ”¹ 2. ì „ì²˜ë¦¬ëœ 'processed' ì»¬ëŸ¼ì„ í™œìš©
df.dropna(subset=['processed'], inplace=True)  # ê²°ì¸¡ê°’ ì œê±°
df['processed'] = df['processed'].astype(str)  # ë¬¸ìì—´ ë³€í™˜

# ğŸ”¹ 3. í˜•íƒœì†Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
df['tokenized'] = df['processed'].apply(lambda x: x.split())

# ğŸ”¹ 4. ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
word_freq = Counter()
for sentence in df['tokenized']:
    word_freq.update(sentence)

# ğŸ”¹ 5. ê³ ë¹ˆë„ ë‹¨ì–´ ì œí•œ (ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ 700ë²ˆ ì´ˆê³¼í•˜ë©´ 700ë²ˆìœ¼ë¡œ ì œí•œ)
THRESHOLD = 700  # ì„ê³„ê°’ (ì´ ê°’ ì´ìƒ ë“±ì¥í•˜ë©´ 700ë²ˆìœ¼ë¡œ ì œí•œ)
def limit_high_freq_words(sentence):
    return [word if word_freq[word] <= THRESHOLD else word * (THRESHOLD // word_freq[word])
            for word in sentence]

df['filtered'] = df['tokenized'].apply(limit_high_freq_words)

# ğŸ”¹ 6. Word2Vec ëª¨ë¸ í•™ìŠµ
sentences = df['filtered'].tolist()
word2vec_model = Word2Vec(
    sentences,
    vector_size=200,  # ì„ë² ë”© ì°¨ì› í¬ê¸°
    window=5,         # ë¬¸ë§¥ ë‹¨ì–´ ë²”ìœ„
    min_count=5,      # ìµœì†Œ ë‹¨ì–´ ë“±ì¥ íšŸìˆ˜
    workers=4,        # ë©€í‹° í”„ë¡œì„¸ì‹± í™œìš©
    epochs=50,        # í•™ìŠµ ì—í¬í¬ ìˆ˜
    sg=0,             # CBOW ëª¨ë¸(0) vs Skip-Gram(1)
    sample=1e-4       # ê³ ë¹ˆë„ ë‹¨ì–´ ìë™ ìƒ˜í”Œë§
)

# ğŸ”¹ 7. ëª¨ë¸ ì €ì¥
word2vec_model.save('./models/word2vec_bible_optimized.model')
print("âœ… Word2Vec ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ê³ ë¹ˆë„ ë‹¨ì–´ ì²˜ë¦¬ ë° ìµœì í™” ì ìš©)")
