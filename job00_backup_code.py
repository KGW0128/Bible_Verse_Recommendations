

#ë°±ì—…ìš© ì½”ë“œ


import pandas as pd
from konlpy.tag import Okt
from gensim.models import Word2Vec
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# ğŸ”¹ 1. CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
bible_file = "./data/merged_bible (2).csv"  # ì„±ê²½ ë°ì´í„° íŒŒì¼
stopwords_file = "./StopWord/stopwords.csv"  # ë¶ˆìš©ì–´ íŒŒì¼

df = pd.read_csv(bible_file)

# ğŸ”¹ 2. ë°ì´í„° ì „ì²˜ë¦¬ (ê²°ì¸¡ê°’ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
df.dropna(inplace=True)
df['content'] = df['content'].astype(str).str.replace(r'[^ê°€-í£\s]', '', regex=True)

# ğŸ”¹ 3. ë¶ˆìš©ì–´ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
stopwords_df = pd.read_csv(stopwords_file)
stopwords = set(stopwords_df['stopword'].tolist())

# ğŸ”¹ 4. í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ, ë¶ˆìš©ì–´ ì œê±°)
okt = Okt()
df['tokenized'] = df['content'].apply(
    lambda x: [word for word, pos in okt.pos(x, stem=True) if pos in ['Noun', 'Verb', 'Adjective']])
df['filtered'] = df['tokenized'].apply(lambda x: [word for word in x if word not in stopwords])  # ë¶ˆìš©ì–´ ì œê±°
df['processed'] = df['filtered'].apply(lambda x: ' '.join(x))  # ë„ì–´ì“°ê¸° ê²°í•©

# ğŸ”¹ 5. TF-IDF ë²¡í„°í™”
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df['processed'])
tfidf_feature_names = vectorizer.get_feature_names_out()
tfidf_scores = dict(zip(tfidf_feature_names, np.array(tfidf_matrix.sum(axis=0)).flatten()))  # ë‹¨ì–´ë³„ ì¤‘ìš”ë„ ì¶”ì¶œ

# ğŸ”¹ 6. Word2Vec ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)
word2vec_model = Word2Vec.load('./models/word2vec_bible.model')


# ğŸ”¹ 7. ê¸°ë„ì œëª©ì—ì„œ ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords(prayer_text, top_n=5):
    # 1ï¸âƒ£ í˜•íƒœì†Œ ë¶„ì„ í›„ ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ
    processed_prayer = [word for word, pos in okt.pos(prayer_text, stem=True) if pos in ['Noun', 'Verb', 'Adjective']]

    # 2ï¸âƒ£ TF-IDF ì ìˆ˜ê°€ ë†’ì€ ë‹¨ì–´ ì¤‘ ìƒìœ„ `top_n`ê°œë§Œ ì„ íƒ
    keyword_candidates = [word for word in processed_prayer if word in tfidf_scores]
    keyword_candidates = sorted(keyword_candidates, key=lambda w: tfidf_scores.get(w, 0), reverse=True)[:top_n]

    return keyword_candidates


# ğŸ”¹ 8. ë§ì”€ ì¶”ì²œ í•¨ìˆ˜ (ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ ê¸°ë°˜)
def recommend_verse(prayer_text):
    keywords = extract_keywords(prayer_text, top_n=5)

    if not keywords:
        print("\nâš ï¸ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    print("\nğŸ” ì„ íƒëœ í‚¤ì›Œë“œ:", keywords)

    # TF-IDF ìœ ì‚¬ë„ ê³„ì‚°
    query_vector = vectorizer.transform([" ".join(keywords)])
    cosine_sim = cosine_similarity(query_vector, tfidf_matrix)
    top_indices = np.argsort(cosine_sim[0])[-3:][::-1]  # ìœ ì‚¬ë„ ë†’ì€ 3ê°œ ì„ íƒ

    print("\nğŸ“– ì¶”ì²œ ì„±ê²½ ë§ì”€:")
    for idx in top_indices:
        print(f"{df.iloc[idx]['book']} {df.iloc[idx]['chapter']}:{df.iloc[idx]['verse']} - {df.iloc[idx]['content']}")


# ğŸ”¹ 9. ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë§ì”€ ì¶”ì²œ ì‹¤í–‰
while True:
    prayer_input = input("\nğŸ™ ê¸°ë„ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
    if prayer_input.lower() == "exit":
        break
    recommend_verse(prayer_input)
