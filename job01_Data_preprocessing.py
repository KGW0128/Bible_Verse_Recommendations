

#ë°ì´í„° ì „ì²˜ë¦¬ ë° ì €ì¥


import pandas as pd
from konlpy.tag import Okt
import collections
import numpy as np

# ğŸ”¹ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
bible_file = "./data/merged_bible.csv"  # ì„±ê²½ ë°ì´í„° íŒŒì¼
stopwords_file = "./StopWord/stopwords.csv"  # ë¶ˆìš©ì–´ íŒŒì¼
output_file = "./data/processed_bible.csv"  # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ

# ğŸ”¹ CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(bible_file)
df.dropna(inplace=True)  # ê²°ì¸¡ê°’ ì œê±°

# ğŸ”¹ íŠ¹ìˆ˜ë¬¸ì ì œê±°
df['content'] = df['content'].astype(str).str.replace(r'[^ê°€-í£\s]', '', regex=True)

# ğŸ”¹ ë¶ˆìš©ì–´ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
stopwords_df = pd.read_csv(stopwords_file)
stopwords = set(stopwords_df['stopword'].tolist())

# ğŸ”¹ í˜•íƒœì†Œ ë¶„ì„ ë° ì „ì²˜ë¦¬
okt = Okt()
df['tokenized'] = df['content'].apply(
    lambda x: [word for word, pos in okt.pos(x, stem=True) if pos in ['Noun', 'Verb', 'Adjective']]
)
df['processed'] = df['tokenized'].apply(lambda x: ' '.join([word for word in x if word not in stopwords]))

# ğŸ”¹ ë¶ˆí•„ìš”í•œ ì—´ ì‚­ì œ
df.drop(columns=['content', 'tokenized'], inplace=True)

# ğŸ”¹ í˜•íƒœì†Œ ë¹ˆë„ ë¶„ì„
all_words = ' '.join(df['processed'].dropna()).split()
word_counts = collections.Counter(all_words)
median_value = np.median(list(word_counts.values()))

# ğŸ”¹ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
print(f"ğŸ”¹ í˜•íƒœì†Œ ì´ ê°œìˆ˜: {len(word_counts)}")
print(f"ğŸ”¹ ì¤‘ìœ„ê°’(ì¤‘ì•™ê°’) ë¹ˆë„: {int(median_value)}")
print("\nğŸ” ê°€ì¥ ë§ì´ ë“±ì¥í•œ í˜•íƒœì†Œ 10ê°œ:")
for word, count in word_counts.most_common(10):
    print(f"{word}: {count}íšŒ")

# ğŸ”¹ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
df.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ! `{output_file}` ì €ì¥ë¨.")
